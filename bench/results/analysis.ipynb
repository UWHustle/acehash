{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6190aa-c4dc-4692-9140-fa9f7528c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0d535-6792-4736-acfa-a209fd76d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "    ('AceHash', ['Lambda', 'Alpha']),\n",
    "    ('BBHash', ['Gamma']),\n",
    "    ('PTHash', ['C', 'Alpha']),\n",
    "    ('VectorMap', []),\n",
    "    ('std::unordered_map', []),\n",
    "    ('absl::flat_hash_map', []),\n",
    "    ('folly::F14FastMap', []),\n",
    "    ('DuckDB', [])\n",
    "]\n",
    "\n",
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    result = []\n",
    "    for family, parameters in algorithms:\n",
    "        df_algorithm = df[df['Algorithm'].str.split(';').str[0] == family].copy()\n",
    "        for i, parameter in enumerate(parameters):\n",
    "            df_algorithm[parameter] = df['Parameters'].str.split(';').str[i].astype(float)\n",
    "        \n",
    "        result.append(df_algorithm)\n",
    "            \n",
    "    return pd.concat(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b9289-83f4-4f55-a7f1-2d77a81c6d2c",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9698dc-e31d-4c1c-ba68-cb59e4b6a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=((4.8, 2.8))\n",
    "\n",
    "df = pd.read_csv('csv/bench_baseline.csv')\n",
    "df['Family'] = df['Algorithm'].str.split('(').str[0]\n",
    "df['Construction throughput'] = 10e6 / df['Build time (s)'] / 1e6\n",
    "df['Evaluation throughput'] = 10e6 / df['Probe time (s)'] / 1e6\n",
    "   \n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.scatterplot(\n",
    "    ax=ax,\n",
    "    data=df,\n",
    "    x='Construction throughput',\n",
    "    y='Evaluation throughput',\n",
    "    hue='Family'\n",
    ")\n",
    "ax.set_xlabel('Construction throughput\\n(million keys per second)')\n",
    "ax.set_ylabel('Evaluation throughput\\n(million keys per second)')\n",
    "ax.set_xlim((0, 13.5))\n",
    "ax.set_ylim((0, 35))\n",
    "ax.legend(title='PHF scheme', loc=(1.05, 0.17))\n",
    "fig.subplots_adjust(left=0.19, right=0.7, bottom=0.25, top=0.97)\n",
    "fig.savefig('pdf/results-baselines-probe-vs-build.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce9533-30ee-4615-a37f-53137f5dda18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameter exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233529a-1b1d-4cac-b1e9-f30f1916bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=((3.3, 2.6))\n",
    "boundaries = {'left': 0.26, 'right': 0.97, 'bottom': 0.24, 'top': 0.9}\n",
    "options = {'linewidth': 2, 'marker': 'o'}\n",
    "# y_axis_label_coords = (-0.21, 0.5)\n",
    "x_ticks = [1.5, 2, 2.5, 3, 3.5, 4, 4.5]\n",
    "\n",
    "df = read_csv('csv/bench_function.csv')\n",
    "df = df[df['Trial'] >= 2]\n",
    "\n",
    "df = df[\n",
    "    (df['Experiment'] == 1)\n",
    "    & (df['Algorithm'] == 'AceHash;1;1;1;0')\n",
    "    & df['Alpha'].isin([0.7, 0.8, 0.9, 0.95, 1])\n",
    "]\n",
    "\n",
    "df['Number of bits per key'] = df['Number of bits'] / df['Number of keys']\n",
    "df['Construction throughput'] = df['Number of keys'] / df['Construction time (s)'] / 1e6\n",
    "df['Serial evaluation throughput'] = 100e6 / df['Serial evaluation time (s)'] / 1e6\n",
    "df['Parallel evaluation throughput'] = 100e6 / df['Parallel evaluation time (s)'] / 1e6\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df,\n",
    "    x='Lambda',\n",
    "    y='Construction throughput',\n",
    "    hue='Alpha',\n",
    "    **options\n",
    ")\n",
    "ax.set_xlabel('$\\\\lambda$')\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_ylabel('Construction throughput\\n(million keys per second)')\n",
    "ax.legend([], [], frameon=False)\n",
    "fig.subplots_adjust(**boundaries)\n",
    "fig.savefig('pdf/results-params-construction-vs-lambda.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df,\n",
    "    x='Lambda',\n",
    "    y='Serial evaluation throughput',\n",
    "    hue='Alpha',\n",
    "    **options\n",
    ")\n",
    "ax.set_xlabel('$\\\\lambda$')\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_ylabel('Evaluation throughput\\n(million keys per second)')\n",
    "ax.legend([], [], frameon=False)\n",
    "fig.subplots_adjust(**boundaries)\n",
    "fig.savefig('pdf/results-params-evaluation-vs-lambda.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.lineplot(\n",
    "    ax=ax,\n",
    "    data=df,\n",
    "    x='Lambda',\n",
    "    y='Number of bits per key',\n",
    "    hue='Alpha',\n",
    "    **options\n",
    ")\n",
    "ax.set_xlabel('$\\\\lambda$')\n",
    "ax.set_ylabel('Size (bits per key)')\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.legend([], [], frameon=False)\n",
    "fig.subplots_adjust(**boundaries)\n",
    "fig.savefig('pdf/results-params-size-vs-lambda.pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(4.8, 0.55))\n",
    "fig.legend(*ax.get_legend_handles_labels(), 'center', ncol=5, title='$\\\\alpha$')\n",
    "fig.savefig('pdf/results-params-legend.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218c53d-6d09-46c7-b485-f4780b31e343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b792c44-417c-410c-85ff-a5f921716447",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=((4.8, 2.4))\n",
    "boundaries = {'left': 0.32, 'right': 0.98, 'bottom': 0.3, 'top': 0.96}\n",
    "options = {'y': 'Algorithm', 'hue': 'Family', 'orient': 'h', 'legend': False}\n",
    "\n",
    "df = read_csv('csv/bench_function.csv')\n",
    "\n",
    "df = df[df['Trial'] >= 2]\n",
    "df['Family'] = df['Algorithm'].str.split(';').str[0]\n",
    "df['Algorithm'] = df['Algorithm'].replace({\n",
    "    'AceHash;0;0;0;0': 'AceHash-O1',\n",
    "    'AceHash;1;0;0;0': 'AceHash-O2',\n",
    "    'AceHash;1;1;0;0': 'AceHash-O3',\n",
    "    'AceHash;1;1;0;1': 'AceHash-O4',\n",
    "    'AceHash;1;1;1;1': 'AceHash-O5',\n",
    "    'BBHash;0': 'BBHash-Serial',\n",
    "    'BBHash;1': 'BBHash-Parallel',\n",
    "    'PTHash;dictionary-dictionary;1': 'PTHash'\n",
    "})\n",
    "\n",
    "df = df[\n",
    "    (df['Algorithm'] != 'AceHash;1;1;1;0')\n",
    "    & (df['Experiment'] == 2)\n",
    "    & (df['Number of keys'] == 10e6)\n",
    "    & df['Parameters'].isin(['2.5;1', '2.000000', '8;0.98'])\n",
    "]\n",
    "\n",
    "df['Number of bits per key'] = df['Number of bits'] / df['Number of keys']\n",
    "df['Construction throughput'] = df['Number of keys'] / df['Construction time (s)'] / 1e6\n",
    "df['Serial evaluation throughput'] = 100e6 / df['Serial evaluation time (s)'] / 1e6\n",
    "df['Parallel evaluation throughput'] = 100e6 / df['Parallel evaluation time (s)'] / 1e6\n",
    "\n",
    "df_evaluation = df[df['Algorithm'] != 'BBHash-Parallel'].copy()\n",
    "df_evaluation['Algorithm'] = df_evaluation['Algorithm'].replace({'BBHash-Serial': 'BBHash'})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df,\n",
    "    x='Construction throughput',\n",
    "    **options\n",
    ")\n",
    "ax.set_xlabel('Construction throughput\\n(millions of keys per second)')\n",
    "fig.subplots_adjust(**boundaries)\n",
    "fig.savefig('pdf/results-micro-construction-vs-algo.pdf')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_evaluation,\n",
    "    x='Serial evaluation throughput',\n",
    "    **options\n",
    ")\n",
    "ax.set_xlabel('Serial evaluation throughput\\n(millions of keys per second)')\n",
    "fig.subplots_adjust(**boundaries)\n",
    "fig.savefig('pdf/results-micro-serial-evaluation-vs-algo.pdf')\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.barplot(\n",
    "    ax=ax,\n",
    "    data=df_evaluation,\n",
    "    x='Parallel evaluation throughput',\n",
    "    **options\n",
    ")\n",
    "ax.set_xlabel('Parallel evaluation throughput\\n(millions of keys per second)')\n",
    "fig.subplots_adjust(**boundaries)\n",
    "fig.savefig('pdf/results-micro-parallel-evaluation-vs-algo.pdf')\n",
    "\n",
    "df = df.groupby('Algorithm').agg({\n",
    "    'Construction throughput': 'mean',\n",
    "    'Serial evaluation throughput': 'mean',\n",
    "    'Parallel evaluation throughput': 'mean'\n",
    "}).transpose()\n",
    "\n",
    "print(df)\n",
    "\n",
    "for level in range(1, 6):\n",
    "    df[f'AceHash-O{level} vs BBHash-Serial'] = df[f'AceHash-O{level}'] / df['BBHash-Serial']\n",
    "    df[f'AceHash-O{level} vs BBHash-Parallel'] = df[f'AceHash-O{level}'] / df['BBHash-Parallel']\n",
    "    df[f'AceHash-O{level} vs PTHash'] = df[f'AceHash-O{level}'] / df['PTHash']\n",
    "\n",
    "print(df['AceHash-O5 vs BBHash-Parallel'])\n",
    "print(df['AceHash-O5 vs PTHash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c9b8c-f33c-4c04-ae04-06432fc9c692",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a8476-2c11-496e-bf72-adf91fcf4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=((3.3, 2.6))\n",
    "boundaries = {'left': 0.28, 'right': 0.97, 'bottom': 0.24, 'top': 0.86}\n",
    "options = {\n",
    "    'x': 'Number of keys',\n",
    "    'hue': 'Algorithm',\n",
    "    'style': 'Algorithm',\n",
    "    'linewidth': 2,\n",
    "    'markers': True\n",
    "}\n",
    "y_axis_label_coords = (-0.19, 0.5)\n",
    "\n",
    "df = read_csv('csv/bench_join.csv')\n",
    "\n",
    "df = df[df['Algorithm'] != 'DuckDB']\n",
    "\n",
    "df['Algorithm'] = df['Algorithm'].replace({\n",
    "    'AceHash;1;1;1;0': 'AceHash',\n",
    "    'BBHash;0': 'BBHash',\n",
    "    'PTHash;dictionary-dictionary;1': 'PTHash',\n",
    "    'std::unordered_map': 'STL',\n",
    "    'absl::flat_hash_map': 'Abseil',\n",
    "    'folly::F14FastMap': 'Folly'\n",
    "})\n",
    "\n",
    "df['Number of bits per key'] = df['Number of bits'] / df['Number of keys']\n",
    "df['Construction throughput'] = df['Number of keys'] / df['Construction time (s)'] / 1e6\n",
    "df['Serial evaluation throughput'] = 100e6 / df['Serial evaluation time (s)'] / 1e6\n",
    "df['Parallel evaluation throughput'] = 100e6 / df['Parallel evaluation time (s)'] / 1e6\n",
    "\n",
    "def plot_retrieval(value_type):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        data=df[df['Value type'] == value_type],\n",
    "        y='Construction time (s)',\n",
    "        **options\n",
    "    )\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Construction time\\n(seconds)')\n",
    "    ax.legend([], [], frameon=False)\n",
    "    fig.subplots_adjust(**boundaries)\n",
    "    fig.savefig(f'pdf/results-retrieval-{value_type}-construction-vs-number.pdf')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        data=df[df['Value type'] == value_type],\n",
    "        y='Serial evaluation throughput',\n",
    "        **options\n",
    "    )\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Serial retrieval throughput\\n(million keys per second)')\n",
    "    ax.legend([], [], frameon=False)\n",
    "    fig.subplots_adjust(**boundaries)\n",
    "    fig.savefig(f'pdf/results-retrieval-{value_type}-serial-evaluation-vs-number.pdf')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.lineplot(\n",
    "        ax=ax,\n",
    "        data=df[df['Value type'] == value_type],\n",
    "        y='Parallel evaluation throughput',\n",
    "        **options\n",
    "    )\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Parallel retrieval throughput\\n(million keys per second)')\n",
    "    ax.legend([], [], frameon=False)\n",
    "    fig.subplots_adjust(**boundaries)\n",
    "    fig.savefig(f'pdf/results-retrieval-{value_type}-parallel-evaluation-vs-number.pdf')\n",
    "\n",
    "    fig = plt.figure(figsize=(7.1, 0.55))\n",
    "    fig.legend(*ax.get_legend_handles_labels(), 'center', ncol=6, title='Method')\n",
    "    fig.savefig('pdf/results-retrieval-legend.pdf', transparent=True)\n",
    "\n",
    "plot_retrieval('m')\n",
    "plot_retrieval('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2e7b3-01a5-484d-acd7-551f8758ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('csv/bench_join.csv')\n",
    "\n",
    "df = df[df['Algorithm'] != 'DuckDB']\n",
    "\n",
    "df['Algorithm'] = df['Algorithm'].replace({\n",
    "    'AceHash;1;1;1;0': 'AceHash',\n",
    "    'BBHash;0': 'BBHash',\n",
    "    'PTHash;dictionary-dictionary;1': 'PTHash',\n",
    "    'std::unordered_map': 'STL',\n",
    "    'absl::flat_hash_map': 'Abseil',\n",
    "    'folly::F14FastMap': 'Folly'\n",
    "})\n",
    "\n",
    "df = df[df['Value type'] == 'm'].copy()\n",
    "\n",
    "df = df.groupby(['Number of keys', 'Algorithm']).agg({\n",
    "    'Construction time (s)': 'mean',\n",
    "    'Serial evaluation time (s)': 'mean',\n",
    "    'Parallel evaluation time (s)': 'mean',\n",
    "}).unstack()\n",
    "\n",
    "\n",
    "print(df['Construction time (s)']['Abseil'] / df['Construction time (s)']['AceHash'])\n",
    "print(df['Serial evaluation time (s)']['Abseil'] / df['Serial evaluation time (s)']['AceHash'])\n",
    "print(df['Parallel evaluation time (s)']['Abseil'] / df['Parallel evaluation time (s)']['AceHash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c351c-e336-4263-8422-63cc8ce70dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf53a8-3125-4cac-9fd2-48f6d319a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=((3.3, 3.2))\n",
    "boundaries = {'left': 0.17, 'right': 0.97, 'bottom': 0.24, 'top': 0.86}\n",
    "options = {\n",
    "    'x': 'Number of keys',\n",
    "    'hue': 'Algorithm',\n",
    "    'style': 'Algorithm',\n",
    "    'linewidth': 2,\n",
    "    'markers': True\n",
    "}\n",
    "\n",
    "df = read_csv('csv/bench_join.csv')\n",
    "\n",
    "df['Algorithm'] = df['Algorithm'].replace({\n",
    "    'AceHash;1;1;1;0': 'AceHash',\n",
    "    'PTHash;dictionary-dictionary;1': 'PTHash',\n",
    "    'std::unordered_map': 'STL',\n",
    "    'absl::flat_hash_map': 'Abseil',\n",
    "    'folly::F14FastMap': 'Folly'\n",
    "})\n",
    "\n",
    "df = df[\n",
    "    (df['Algorithm'] != 'STL')\n",
    "    & (df['Algorithm'] != 'Folly')\n",
    "    & (df['Algorithm'] != 'BBHash;0')\n",
    "]\n",
    "\n",
    "df['Query time (s)'] = df['Construction time (s)'] + df['Serial evaluation time (s)']\n",
    "\n",
    "def plot_join(value_type):\n",
    "    speedups = df[df['Value type'] == value_type].groupby(['Number of keys', 'Algorithm']).agg({'Query time (s)': 'mean'}).unstack()\n",
    "    speedups = speedups['Query time (s)'][['PTHash', 'Abseil', 'DuckDB']].min(axis=1) / speedups['Query time (s)']['AceHash']\n",
    "    print(speedups)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=figsize, sharex=True, gridspec_kw={'height_ratios': [5, 2]})\n",
    "    sns.lineplot(\n",
    "        data=df[df['Value type'] == value_type],\n",
    "        ax=ax1,\n",
    "        y='Query time (s)',\n",
    "        **options\n",
    "    )\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_ylim((0.45 if value_type == 'h' else 0.55, 100))\n",
    "    ax1.set_ylabel('Query time\\n(seconds)')\n",
    "    ax1.legend([], [], frameon=False)\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=speedups,\n",
    "        ax=ax2,\n",
    "        linewidth=2,\n",
    "        marker='o'\n",
    "    )\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_xlabel('Number of build tuples')\n",
    "    ax2.set_ylim((0.6, 3.0) if value_type == 'h' else (0.5, 2.3))\n",
    "    ax2.set_ylabel('Speedup\\nover best')\n",
    "\n",
    "    fig.align_labels()\n",
    "    fig.subplots_adjust(\n",
    "        left=0.25,\n",
    "        right=0.98,\n",
    "        bottom=0.18,\n",
    "        top=0.95\n",
    "    )\n",
    "    fig.savefig(f'pdf/results-query-join-{value_type}-time-vs-number.pdf')\n",
    "    \n",
    "plot_join('h')\n",
    "plot_join('m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c1ab3-64fc-4df9-afca-4d25f4d89c15",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae41dff-cba4-414b-8c9c-bf3af1599531",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=((3.3, 3.2))\n",
    "options = {\n",
    "    'x': 'Key cardinality',\n",
    "    'hue': 'Algorithm',\n",
    "    'style': 'Algorithm',\n",
    "    'linewidth': 2,\n",
    "    'markers': True\n",
    "}\n",
    "\n",
    "df = read_csv('csv/bench_aggregate.csv')\n",
    "\n",
    "df['Algorithm'] = df['Algorithm'].replace({\n",
    "    'AceHash;1;1;1;0': 'AceHash',\n",
    "    'PTHash;dictionary-dictionary;1': 'PTHash',\n",
    "    'std::unordered_map': 'STL',\n",
    "    'absl::flat_hash_map': 'Abseil',\n",
    "    'folly::F14FastMap': 'Folly'\n",
    "})\n",
    "\n",
    "df = df[\n",
    "    (df['Algorithm'] != 'STL')\n",
    "    & (df['Algorithm'] != 'Folly')\n",
    "    & (df['Algorithm'] != 'BBHash;0')\n",
    "    & (df['Value type'] == 'm')\n",
    "]\n",
    "\n",
    "df['Query time (s)'] = df['Build time (s)'] + df['Serial aggregate time (s)']\n",
    "\n",
    "speedups = df.groupby(['Key cardinality', 'Algorithm']).agg({'Query time (s)': 'mean'}).unstack()\n",
    "speedups = speedups['Query time (s)'][['PTHash', 'Abseil', 'DuckDB']].min(axis=1) / speedups['Query time (s)']['AceHash']\n",
    "print(speedups)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=figsize, sharex=True, gridspec_kw={'height_ratios': [5, 2]})\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df,\n",
    "    ax=ax1,\n",
    "    y='Query time (s)',\n",
    "    **options\n",
    ")\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim((0.5, 100))\n",
    "ax1.set_ylabel('Query time\\n(seconds)')\n",
    "ax1.legend([], [], frameon=False)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=speedups,\n",
    "    ax=ax2,\n",
    "    linewidth=2,\n",
    "    marker='o'\n",
    ")\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlabel('Number of groups')\n",
    "ax2.set_ylim((0.3, 2.8))\n",
    "ax2.set_ylabel('Speedup\\nover best')\n",
    "\n",
    "fig.align_labels()\n",
    "fig.subplots_adjust(\n",
    "    left=0.25,\n",
    "    right=0.98,\n",
    "    bottom=0.18,\n",
    "    top=0.95\n",
    ")\n",
    "fig.savefig('pdf/results-query-aggregate-time-vs-number.pdf')\n",
    "\n",
    "fig = plt.figure(figsize=(5.0, 0.55))\n",
    "fig.legend(*ax1.get_legend_handles_labels(), 'center', ncol=6, title='Method')\n",
    "fig.savefig('pdf/results-query-legend.pdf', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71e8f9-e5e8-4895-9262-de9f89c40bb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbbaa3-d494-4874-a5e4-923bfead3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(4.8, 2.0)\n",
    "\n",
    "df = pd.read_csv('csv/bench_intro.csv')\n",
    "df = df[df['Alpha'] >= 0.2]\n",
    "df['Throughput'] = 10e6 / df['Time (s)'] / 1e6\n",
    "\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.lineplot(\n",
    "    data=df,\n",
    "    x='Alpha',\n",
    "    y='Throughput',\n",
    "    hue='Algorithm',\n",
    "    style='Algorithm',\n",
    "    linewidth=2\n",
    ")\n",
    "ax.set_xlabel('Load factor')\n",
    "ax.set_ylabel('Throughput (million\\nlookups per second)')\n",
    "ax.legend(title='Algorithm', loc=(1.03, 0.22))\n",
    "fig.subplots_adjust(left=0.165, right=0.68, bottom=0.24, top=0.94)\n",
    "fig.savefig('pdf/results-intro.pdf')\n",
    "\n",
    "print(df[df['Algorithm'] == 'Conventional']['Throughput'].max())\n",
    "print(df[df['Algorithm'] == 'AceHash']['Throughput'].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
